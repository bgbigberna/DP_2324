{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6d6342-a716-498d-92c3-d0b73ca65180",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654f5550-cccb-49c1-a29c-c1fa3b4141cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0               1  2\n",
      "0  O14842   CHEMBL2022243  4\n",
      "1  O14842   CHEMBL2022244  6\n",
      "2  O14842   CHEMBL2022245  2\n",
      "3  O14842   CHEMBL2022246  1\n",
      "4  O14842   CHEMBL2022247  4\n",
      "------------------------------------------\n",
      "        0               1  2\n",
      "0  O14842   CHEMBL2022258  0\n",
      "1  O14842   CHEMBL2047161  0\n",
      "2  O14842   CHEMBL2047163  0\n",
      "3  O14842   CHEMBL2047168  0\n",
      "4  O14842   CHEMBL2047169  0\n",
      "------------------------------------------\n",
      "Number of molecular fingerprints: 73865\n",
      "------------------------------------------\n",
      "ChEMBL ID: CHEMBL2022243, Fingerprint: [10, 38, 50, 80, 107, 113, 180, 217, 315, 322, 365, 366, 389, 400, 545, 602, 650, 654, 679, 695, 713, 718, 736, 745, 797, 799, 807, 850, 875, 926, 935, 1004, 1019, 1027, 1035, 1039, 1050, 1057, 1066, 1088, 1118, 1121, 1160, 1171, 1173, 1179, 1236, 1237, 1325, 1380, 1391, 1419, 1442, 1452, 1456, 1476, 1501, 1611, 1660, 1722, 1737, 1738, 1746, 1747, 1750, 1754, 1758, 1799, 1873, 1917, 1999, 2021]\n",
      "------------------------------------------\n",
      "ChEMBL ID: CHEMBL2022244, Fingerprint: [10, 38, 50, 80, 107, 113, 180, 217, 315, 322, 365, 366, 389, 400, 473, 545, 556, 602, 650, 654, 695, 718, 736, 745, 778, 799, 807, 850, 875, 926, 935, 1004, 1019, 1027, 1028, 1035, 1039, 1050, 1057, 1066, 1088, 1112, 1118, 1160, 1171, 1173, 1179, 1236, 1237, 1325, 1380, 1391, 1417, 1419, 1452, 1456, 1460, 1476, 1501, 1544, 1611, 1660, 1722, 1737, 1738, 1746, 1747, 1750, 1754, 1799, 1863, 1873, 1917, 1999, 2021]\n",
      "------------------------------------------\n",
      "ChEMBL ID: CHEMBL2022245, Fingerprint: [10, 38, 50, 80, 104, 107, 113, 180, 184, 217, 310, 315, 322, 365, 366, 389, 400, 545, 556, 602, 650, 654, 695, 718, 736, 745, 799, 807, 850, 875, 890, 926, 935, 1004, 1019, 1027, 1028, 1035, 1039, 1050, 1057, 1066, 1088, 1112, 1118, 1160, 1171, 1173, 1179, 1236, 1237, 1325, 1380, 1391, 1419, 1452, 1456, 1476, 1501, 1544, 1599, 1611, 1660, 1722, 1737, 1738, 1746, 1747, 1750, 1754, 1799, 1863, 1873, 1917, 1981, 1999, 2021]\n",
      "------------------------------------------\n",
      "ChEMBL ID: CHEMBL2022246, Fingerprint: [10, 38, 50, 80, 107, 113, 118, 123, 217, 315, 322, 325, 366, 384, 389, 465, 488, 545, 550, 650, 654, 656, 695, 718, 736, 745, 807, 816, 850, 875, 914, 1035, 1039, 1057, 1066, 1088, 1141, 1160, 1171, 1173, 1174, 1179, 1233, 1237, 1269, 1275, 1349, 1357, 1380, 1391, 1419, 1452, 1501, 1503, 1580, 1674, 1722, 1733, 1737, 1747, 1750, 1754, 1799, 1803, 1808, 1873, 1896, 1917, 1999, 2021, 2041]\n",
      "------------------------------------------\n",
      "ChEMBL ID: CHEMBL2022247, Fingerprint: [10, 22, 38, 50, 66, 80, 107, 113, 160, 180, 217, 315, 322, 366, 389, 441, 491, 545, 640, 650, 654, 656, 695, 718, 736, 745, 807, 850, 875, 926, 946, 1004, 1010, 1019, 1027, 1035, 1039, 1050, 1057, 1066, 1088, 1116, 1160, 1171, 1173, 1179, 1237, 1346, 1380, 1391, 1419, 1452, 1501, 1502, 1509, 1611, 1689, 1722, 1737, 1746, 1747, 1750, 1754, 1799, 1867, 1873, 1887, 1905, 1917, 1923, 1999, 2021]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "activity_train = pd.read_csv('activity_train.csv', header=None)\n",
    "activity_test_blanked = pd.read_csv('activity_test_blanked.csv', header=None)\n",
    "\n",
    "with open('mol_bits.pkl', 'rb') as f:\n",
    "    mol_bits = pickle.load(f)\n",
    "\n",
    "print(activity_train.head())\n",
    "print(\"------------------------------------------\")\n",
    "print(activity_test_blanked.head())\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "print(f\"Number of molecular fingerprints: {len(mol_bits)}\")\n",
    "for key, value in list(mol_bits.items())[:5]:\n",
    "    print(\"------------------------------------------\")\n",
    "    print(f\"ChEMBL ID: {key}, Fingerprint: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47daf51-68d5-4b52-acf6-9c1856420bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity Train Dataset:\n",
      "        0              1  2                                        Fingerprint\n",
      "0  O14842  CHEMBL2022243  4  [10, 38, 50, 80, 107, 113, 180, 217, 315, 322,...\n",
      "1  O14842  CHEMBL2022244  6  [10, 38, 50, 80, 107, 113, 180, 217, 315, 322,...\n",
      "2  O14842  CHEMBL2022245  2  [10, 38, 50, 80, 104, 107, 113, 180, 184, 217,...\n",
      "3  O14842  CHEMBL2022246  1  [10, 38, 50, 80, 107, 113, 118, 123, 217, 315,...\n",
      "4  O14842  CHEMBL2022247  4  [10, 22, 38, 50, 66, 80, 107, 113, 160, 180, 2...\n",
      "Activity Test Blanked Dataset:\n",
      "        0              1  2                                        Fingerprint\n",
      "0  O14842  CHEMBL2022258  0  [22, 38, 39, 50, 66, 80, 107, 113, 160, 180, 2...\n",
      "1  O14842  CHEMBL2047161  0  [22, 38, 39, 50, 66, 80, 107, 113, 119, 160, 1...\n",
      "2  O14842  CHEMBL2047163  0  [3, 22, 38, 39, 50, 66, 80, 107, 113, 160, 166...\n",
      "3  O14842  CHEMBL2047168  0  [13, 22, 38, 66, 80, 107, 113, 133, 160, 180, ...\n",
      "4  O14842  CHEMBL2047169  0  [13, 22, 38, 66, 80, 107, 113, 133, 160, 180, ...\n",
      "Molecular Fingerprint Dataset:\n",
      "     Molecule_ID                                        Fingerprint\n",
      "0  CHEMBL2022243  [10, 38, 50, 80, 107, 113, 180, 217, 315, 322,...\n",
      "1  CHEMBL2022244  [10, 38, 50, 80, 107, 113, 180, 217, 315, 322,...\n",
      "2  CHEMBL2022245  [10, 38, 50, 80, 104, 107, 113, 180, 184, 217,...\n",
      "3  CHEMBL2022246  [10, 38, 50, 80, 107, 113, 118, 123, 217, 315,...\n",
      "4  CHEMBL2022247  [10, 22, 38, 50, 66, 80, 107, 113, 160, 180, 2...\n"
     ]
    }
   ],
   "source": [
    "# Convert mol_bits to DataFrame\n",
    "mol_bits_df = pd.DataFrame(mol_bits.items(), columns=['Molecule_ID', 'Fingerprint'])\n",
    "\n",
    "# Remove leading space from molecule IDs in activity datasets\n",
    "activity_train[1] = activity_train[1].str.strip()\n",
    "activity_test_blanked[1] = activity_test_blanked[1].str.strip()\n",
    "\n",
    "# Merge activity datasets with molecular fingerprints\n",
    "activity_train = pd.merge(activity_train, mol_bits_df, left_on=1, right_on='Molecule_ID', how='left')\n",
    "activity_test_blanked = pd.merge(activity_test_blanked, mol_bits_df, left_on=1, right_on='Molecule_ID', how='left')\n",
    "\n",
    "# Drop redundant columns\n",
    "activity_train.drop(['Molecule_ID'], axis=1, inplace=True)\n",
    "activity_test_blanked.drop(['Molecule_ID'], axis=1, inplace=True)\n",
    "\n",
    "# Explore the data\n",
    "print(\"Activity Train Dataset:\")\n",
    "print(activity_train.head())\n",
    "print(\"Activity Test Blanked Dataset:\")\n",
    "print(activity_test_blanked.head())\n",
    "print(\"Molecular Fingerprint Dataset:\")\n",
    "print(mol_bits_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722719b4-487b-4533-abe5-d4a2703e6544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of activity_train_svd: (135711, 50)\n",
      "Shape of activity_test_blanked_svd: (4628, 50)\n",
      "Shape of cosine similarity matrix: (135711, 4628)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define function to pad or truncate fingerprint arrays to a fixed length\n",
    "def pad_fingerprint(fingerprint, length=100):\n",
    "    if len(fingerprint) < length:\n",
    "        return np.pad(fingerprint, (0, length - len(fingerprint)), mode='constant')\n",
    "    else:\n",
    "        return fingerprint[:length]\n",
    "\n",
    "# Pad or truncate molecular fingerprints to a fixed length\n",
    "activity_train['Fingerprint'] = activity_train['Fingerprint'].apply(pad_fingerprint)\n",
    "activity_test_blanked['Fingerprint'] = activity_test_blanked['Fingerprint'].apply(pad_fingerprint)\n",
    "\n",
    "# Convert molecular fingerprints to 2D array\n",
    "activity_train_array = np.stack(activity_train['Fingerprint'].values)\n",
    "activity_test_blanked_array = np.stack(activity_test_blanked['Fingerprint'].values)\n",
    "\n",
    "# Perform clustering using K-means algorithm\n",
    "kmeans = KMeans(n_clusters=5, n_init=10, random_state=42)  # Adjust number of clusters as needed\n",
    "activity_train['Cluster'] = kmeans.fit_predict(activity_train_array)\n",
    "activity_test_blanked['Cluster'] = kmeans.predict(activity_test_blanked_array)\n",
    "\n",
    "# Apply SVD for dimensionality reduction\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)  # Adjust number of components as needed\n",
    "svd.fit(activity_train_array)\n",
    "activity_train_svd = svd.transform(activity_train_array)\n",
    "activity_test_blanked_svd = svd.transform(activity_test_blanked_array)\n",
    "\n",
    "# Calculate cosine similarity between molecular fingerprints\n",
    "cos_sim = cosine_similarity(activity_train_array, activity_test_blanked_array)\n",
    "\n",
    "# Print shapes of transformed data\n",
    "print(\"Shape of activity_train_svd:\", activity_train_svd.shape)\n",
    "print(\"Shape of activity_test_blanked_svd:\", activity_test_blanked_svd.shape)\n",
    "print(\"Shape of cosine similarity matrix:\", cos_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c2538a-5d87-4b8f-99b3-dd64e9f03d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(activity_train_svd, activity_train[2], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac54fc0-a883-4fa1-8fd4-be6705c83a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 6.8410603456022825\n",
      "Linear Regression - Mean Squared Error: 7.942160330709447\n",
      "Decision Tree - Mean Squared Error: 9.625827071269388\n",
      "Gradient Boosting - Mean Squared Error: 7.823133696828843\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, y_pred)\n",
    "    print(f\"{name} - Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf10bb68-a288-4e46-9398-4e6ed4998250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Define hyperparameters grid for each model\\nparam_grid = {\\n    \\'Decision Tree\\': {\\'max_depth\\': [None, 5, 10, 20]},\\n    \\'Random Forest\\': {\\'n_estimators\\': [100, 200, 300], \\'max_depth\\': [None, 10, 20]},\\n    \\'Gradient Boosting\\': {\\'n_estimators\\': [100, 200, 300], \\'learning_rate\\': [0.1, 0.05, 0.01]}\\n }\\n# Perform hyperparameter tuning using grid search\\nbest_models = {}\\nfor name, model in models.items():\\n    if name in param_grid:\\n        grid_search = GridSearchCV(model, param_grid[name], cv=5, scoring=\\'neg_mean_squared_error\\')\\n        grid_search.fit(X_train, y_train)\\n        best_model = grid_search.best_estimator_\\n        best_models[name] = best_model\\n        print(f\"Best hyperparameters for {name}: {grid_search.best_params_}\")\\n        print(f\"Best mean squared error for {name}: {-grid_search.best_score_}\")'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Define hyperparameters grid for each model\n",
    "param_grid = {\n",
    "    'Decision Tree': {'max_depth': [None, 5, 10, 20]},\n",
    "    'Random Forest': {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]},\n",
    "    'Gradient Boosting': {'n_estimators': [100, 200, 300], 'learning_rate': [0.1, 0.05, 0.01]}\n",
    " }\n",
    "# Perform hyperparameter tuning using grid search\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    if name in param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid[name], cv=5, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_models[name] = best_model\n",
    "        print(f\"Best hyperparameters for {name}: {grid_search.best_params_}\")\n",
    "        print(f\"Best mean squared error for {name}: {-grid_search.best_score_}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a41e506-6c5d-49a2-809d-04864f2e3fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the best model based on validation performance\n",
    "best_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "best_model.fit(activity_train_svd, activity_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b7c84ad-a7fc-4342-b827-b05545d5a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict activities for the test set\n",
    "activity_test_blanked[2] = best_model.predict(activity_test_blanked_svd)\n",
    "\n",
    "# Save the predictions\n",
    "activity_test_blanked.to_csv('activity_test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b5863e-1c74-4043-94e1-4cd7727f4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'activity_test_predictions.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select the first two columns\n",
    "df_selected = df.iloc[:, :3]\n",
    "\n",
    "# Save the new DataFrame to a new CSV file\n",
    "output_file_path = 'activity_test_blanked_predicted.csv'  # Replace with the desired path for the output file\n",
    "df_selected.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dd44a-a237-4871-bb46-3038f9fca95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
